{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from lstm_classifier import LSTMClassifier\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from custom_dataset import CustomDataset\n",
    "import argparse\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Funciones'''\n",
    "# Función que levanta el archivo data y lo transforma en una lista de (sentence, label)\n",
    "def get_data_splitted(data):\n",
    "    instances = []\n",
    "    labels = []\n",
    "    with open(data, 'r') as sentences:\n",
    "        for line in sentences:\n",
    "            instances.append(get_sentence_splitted(line))\n",
    "            labels.append(get_label(line))\n",
    "    return instances, labels\n",
    "\n",
    "def get_label(line):\n",
    "    return line.split()[0].replace('__label__', '')\n",
    "\n",
    "def get_sentence_splitted(line):\n",
    "    line_split = line.split();\n",
    "    res = []\n",
    "    for val in range(1, len(line_split)):\n",
    "        res.append(line_split[val])\n",
    "    return res;\n",
    "\n",
    "### Función que toma un jsonl y agrega las palabras a mi mapa de word_to_integer\n",
    "def add_words_to_map(sentences, word_to_ix):\n",
    "    for sentence in sentences:\n",
    "        for word in sentence.split():\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "    return word_to_ix\n",
    "\n",
    "### Función que recibe la lista de archivos txt, convierte cada uno en una lista de oraciones de Python y se encarga de llamar a add_words_to_map\n",
    "def create_map(txt_list):\n",
    "    word_to_ix = {}\n",
    "    for input_file in txt_list:\n",
    "        with open(input_file, 'r') as infile:\n",
    "            sentences = []\n",
    "            for line in infile:\n",
    "                sentences.append(line)\n",
    "            word_to_ix = add_words_to_map(sentences, word_to_ix)\n",
    "    return word_to_ix\n",
    "\n",
    "# Función que crea un vector contando la cantidad de apariciones de las palabras en una oración.\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix)) # Vector de ceros\n",
    "    for word in sentence.split():\n",
    "        vec[word_to_ix[word]] += 1 # Por cada aparición de una palabra, le sumo uno\n",
    "    return vec.view(1, -1) # Vector de tamaño 1 x n, donde n es inferido por el tamaño de palabras\n",
    "\n",
    "# Función que wrappea la variable en un tensor. Básicamente, le pasas la lista de labels y tu label en particular, y te devuelve un tensor con el valor 0, 1 ó 2 adentro.\n",
    "def make_target(label, label_to_ix):\n",
    "    return label_to_ix[label]\n",
    "\n",
    "def get_label_by_item(item):\n",
    "    for label, value in label_to_ix.items():\n",
    "        if(value == item):\n",
    "            return label\n",
    "    return None\n",
    "\n",
    "def calculate_error_rate(predicted, label_batch):\n",
    "    counter = 0\n",
    "    ok = 0\n",
    "    for instance,label in zip(predicted, label_batch):\n",
    "        if(instance.item() == label.item()):\n",
    "            ok += 1\n",
    "        counter += 1\n",
    "\n",
    "    return ok / counter\n",
    "\n",
    "def define_batch_size(batch_size, file):\n",
    "    size = 0\n",
    "    with open(file, 'r') as infile:\n",
    "        size = len(infile.readlines())\n",
    "    while True:\n",
    "        if(size % batch_size == 0):\n",
    "            return batch_size\n",
    "        batch_size = batch_size - 1\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = list(map(lambda w: to_ix[w], seq))\n",
    "    return idxs\n",
    "\n",
    "def get_result_label(result, label_to_ix):\n",
    "    for label, number in label_to_ix.items():    # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "        if result == number:\n",
    "            return \"__label__\"+label\n",
    "\n",
    "def get_tensor_data(data_inst, data_lab, word_to_ix, label_to_ix, use_labels=True):\n",
    "    instances = []\n",
    "    labels = []\n",
    "    for instance, label in zip(data_inst, data_lab):\n",
    "        instances.append(prepare_sequence(instance, word_to_ix))\n",
    "        if(use_labels):\n",
    "            labels.append(make_target(label, label_to_ix))\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return instances, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funciones utilizadas para el collate_fn de CustomDataset\n",
    "def get_max_length(x):\n",
    "    return len(max(x, key=len))\n",
    "\n",
    "def pad_sequence(seq):\n",
    "    def _pad(_it, _max_len):\n",
    "        return [0] * (_max_len - len(_it)) + _it\n",
    "    return [_pad(it, get_max_length(seq)) for it in seq]\n",
    "\n",
    "def custom_collate(batch):\n",
    "    transposed = zip(*batch)\n",
    "    lst = []\n",
    "    for samples in transposed:\n",
    "        if isinstance(samples[0], int):\n",
    "            lst.append(torch.LongTensor(samples))\n",
    "        elif isinstance(samples[0], float):\n",
    "            lst.append(torch.DoubleTensor(samples))\n",
    "        elif isinstance(samples[0], list):\n",
    "            lst.append(torch.LongTensor(pad_sequence(samples)))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOGGING = False\n",
    "SHUFFLE = True # used to shuffle the trainset before each epoc\n",
    "# DATA = 30000 # TODO: this datasize is hardcoded\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 50\n",
    "BATCH_SIZE = 50\n",
    "EPOCH_SIZE = 15\n",
    "CLIP = 5 # normalizing lstm vector values when backpropagating to avoid exploding gradients\n",
    "LEARNING_RATE = 1\n",
    "DROPOUT=0.5\n",
    "NUM_LAYERS=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEV_SENTENCES = \"./dev_sentences.txt\"\n",
    "TRAIN_SENTENCES = \"./train_sentences.txt\"\n",
    "TEST_SENTENCES = \"./test_sentences.txt\"\n",
    "\n",
    "DEV_DATA = \"./dev_data.txt\"\n",
    "TRAIN_DATA = \"./train_data.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Creación del modelo '''\n",
    "### Defino la cantidad de palabras y la cantidad de labels\n",
    "label_to_ix = { \"neutral\": 0, \"contradiction\": 1, \"entailment\": 2 }\n",
    "word_to_ix = create_map([DEV_SENTENCES, TRAIN_SENTENCES, TEST_SENTENCES])\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "\n",
    "# Creo mi modelo, defino la loss function, y la función de optimización\n",
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, NUM_LABELS, BATCH_SIZE, DROPOUT, NUM_LAYERS)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Entrenamiento'''\n",
    "# Usually you want to pass over the training data several times.\n",
    "# 100 is much bigger than on a real data set, but real datasets have more than\n",
    "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable (NOTA DE MARISCO: tarda algunos minutos cada vuelta).\n",
    "instances, labels = get_data_splitted(TRAIN_DATA)\n",
    "instances, labels = get_tensor_data(instances, labels, word_to_ix, label_to_ix)\n",
    "\n",
    "# instances = instances[0:DATA]\n",
    "# labels = labels[0:DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_data = CustomDataset(instances, labels)\n",
    "train_loader = DataLoader(dataset=tensor_data, batch_size=BATCH_SIZE, shuffle=SHUFFLE, collate_fn=custom_collate, drop_last=True) #TODO shuffle?\n",
    "\n",
    "sentences, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgiudice/meliXos/src/lstm_classifier.py:32: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  embeds = embeds.view(len(sentence), self.batch_size, -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Long(16!, 50!),\n",
      "      %1 : Float(31997, 100),\n",
      "      %2 : Float(200, 100),\n",
      "      %3 : Float(200, 50),\n",
      "      %4 : Float(200),\n",
      "      %5 : Float(200),\n",
      "      %6 : Float(200, 100),\n",
      "      %7 : Float(200, 50),\n",
      "      %8 : Float(200),\n",
      "      %9 : Float(200),\n",
      "      %10 : Float(200, 100),\n",
      "      %11 : Float(200, 50),\n",
      "      %12 : Float(200),\n",
      "      %13 : Float(200),\n",
      "      %14 : Float(200, 100),\n",
      "      %15 : Float(200, 50),\n",
      "      %16 : Float(200),\n",
      "      %17 : Float(200),\n",
      "      %18 : Float(3, 100),\n",
      "      %19 : Float(3)):\n",
      "  %20 : Float(16, 50, 100) = onnx::Gather(%1, %input.1), scope: LSTMClassifier/Embedding[word_embeddings]\n",
      "  %21 : Tensor = onnx::Constant[value= 16  50  -1 [ Variable[CPUType]{3} ]](), scope: LSTMClassifier\n",
      "  %22 : Float(16, 50, 100) = onnx::Reshape(%20, %21), scope: LSTMClassifier\n",
      "  %23 : Tensor = onnx::Constant[value=<Tensor>]()\n",
      "  %24 : Tensor = onnx::Constant[value=<Tensor>]()\n",
      "  %25 : Tensor? = prim::Constant(), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %26 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%2), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %27 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%2), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %28 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%2), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %29 : Tensor = onnx::Concat[axis=0](%26, %27, %28), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %30 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%3), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %31 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%3), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %32 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%3), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %33 : Tensor = onnx::Concat[axis=0](%30, %31, %32), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %34 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%4), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %35 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%4), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %36 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%4), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %37 : Tensor = onnx::Concat[axis=0](%34, %35, %36), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %38 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%5), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %39 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%5), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %40 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%5), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %41 : Tensor = onnx::Concat[axis=0](%38, %39, %40), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %42 : Tensor = onnx::Concat[axis=0](%37, %41), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %43 : Tensor = onnx::Unsqueeze[axes=[0]](%29), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %44 : Tensor = onnx::Unsqueeze[axes=[0]](%33), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %45 : Tensor = onnx::Unsqueeze[axes=[0]](%42), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %46 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%6), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %47 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%6), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %48 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%6), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %49 : Tensor = onnx::Concat[axis=0](%46, %47, %48), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %50 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%7), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %51 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%7), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %52 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%7), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %53 : Tensor = onnx::Concat[axis=0](%50, %51, %52), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %54 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%8), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %55 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%8), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %56 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%8), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %57 : Tensor = onnx::Concat[axis=0](%54, %55, %56), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %58 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%9), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %59 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%9), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %60 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%9), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %61 : Tensor = onnx::Concat[axis=0](%58, %59, %60), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %62 : Tensor = onnx::Concat[axis=0](%57, %61), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %63 : Tensor = onnx::Unsqueeze[axes=[0]](%49), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %64 : Tensor = onnx::Unsqueeze[axes=[0]](%53), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %65 : Tensor = onnx::Unsqueeze[axes=[0]](%62), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %66 : Tensor = onnx::Concat[axis=0](%43, %63), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %67 : Tensor = onnx::Concat[axis=0](%44, %64), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %68 : Tensor = onnx::Concat[axis=0](%45, %65), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %69 : Tensor = onnx::Slice[axes=[0], ends=[2], starts=[0]](%23), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %70 : Tensor = onnx::Slice[axes=[0], ends=[2], starts=[0]](%24), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %71 : Tensor, %72 : Tensor, %73 : Tensor = onnx::LSTM[direction=\"bidirectional\", hidden_size=50](%22, %66, %67, %68, %25, %69, %70), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %74 : Tensor = onnx::Transpose[perm=[0, 2, 1, 3]](%71), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %75 : Tensor = onnx::Constant[value= 0  0 -1 [ Variable[CPUType]{3} ]](), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %76 : Tensor = onnx::Reshape(%74, %75), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %77 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%10), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %78 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%10), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %79 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%10), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %80 : Tensor = onnx::Concat[axis=0](%77, %78, %79), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %81 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%11), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %82 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%11), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %83 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%11), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %84 : Tensor = onnx::Concat[axis=0](%81, %82, %83), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %85 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%12), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %86 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%12), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %87 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%12), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %88 : Tensor = onnx::Concat[axis=0](%85, %86, %87), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %89 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%13), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %90 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%13), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %91 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%13), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %92 : Tensor = onnx::Concat[axis=0](%89, %90, %91), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %93 : Tensor = onnx::Concat[axis=0](%88, %92), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %94 : Tensor = onnx::Unsqueeze[axes=[0]](%80), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %95 : Tensor = onnx::Unsqueeze[axes=[0]](%84), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %96 : Tensor = onnx::Unsqueeze[axes=[0]](%93), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %97 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%14), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %98 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%14), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %99 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%14), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %100 : Tensor = onnx::Concat[axis=0](%97, %98, %99), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %101 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%15), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %102 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%15), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %103 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%15), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %104 : Tensor = onnx::Concat[axis=0](%101, %102, %103), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %105 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%16), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %106 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%16), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %107 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%16), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %108 : Tensor = onnx::Concat[axis=0](%105, %106, %107), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %109 : Tensor = onnx::Slice[axes=[0], ends=[50], starts=[0]](%17), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %110 : Tensor = onnx::Slice[axes=[0], ends=[200], starts=[150]](%17), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %111 : Tensor = onnx::Slice[axes=[0], ends=[150], starts=[50]](%17), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %112 : Tensor = onnx::Concat[axis=0](%109, %110, %111), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %113 : Tensor = onnx::Concat[axis=0](%108, %112), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %114 : Tensor = onnx::Unsqueeze[axes=[0]](%100), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %115 : Tensor = onnx::Unsqueeze[axes=[0]](%104), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %116 : Tensor = onnx::Unsqueeze[axes=[0]](%113), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %117 : Tensor = onnx::Concat[axis=0](%94, %114), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %118 : Tensor = onnx::Concat[axis=0](%95, %115), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %119 : Tensor = onnx::Concat[axis=0](%96, %116), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %120 : Tensor = onnx::Slice[axes=[0], ends=[4], starts=[2]](%23), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %121 : Tensor = onnx::Slice[axes=[0], ends=[4], starts=[2]](%24), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %122 : Tensor, %123 : Tensor, %124 : Tensor = onnx::LSTM[direction=\"bidirectional\", hidden_size=50](%76, %117, %118, %119, %25, %120, %121), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %125 : Tensor = onnx::Transpose[perm=[0, 2, 1, 3]](%122), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %126 : Tensor = onnx::Constant[value= 0  0 -1 [ Variable[CPUType]{3} ]](), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %127 : Float(16, 50, 100) = onnx::Reshape(%125, %126), scope: LSTMClassifier/LSTM[lstm]\n",
      "  %128 : Long() = onnx::Constant[value={-1}](), scope: LSTMClassifier\n",
      "  %129 : Float(50, 100) = onnx::Gather[axis=0](%127, %128), scope: LSTMClassifier\n",
      "  %130 : Float(100!, 3!) = onnx::Transpose[perm=[1, 0]](%18), scope: LSTMClassifier/Linear[hidden2label]\n",
      "  %131 : Float(50, 3) = onnx::Gemm[alpha=1, beta=1](%129, %130, %19), scope: LSTMClassifier/Linear[hidden2label]\n",
      "  %132 : Float(50, 3) = onnx::LogSoftmax[axis=1](%131), scope: LSTMClassifier\n",
      "  return (%132)\n",
      "\n",
      "EPOCH 0 STARTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ENDED:  accuracy: 0.68\n",
      "EPOCH 1 STARTED\n",
      "EPOCH 1 ENDED:  accuracy: 0.66\n",
      "EPOCH 2 STARTED\n",
      "EPOCH 2 ENDED:  accuracy: 0.48\n",
      "EPOCH 3 STARTED\n"
     ]
    }
   ],
   "source": [
    "# send model to tensorboard\n",
    "with SummaryWriter(\"./hello_tf_board/\") as writer:\n",
    "    writer.add_graph(model, sentences.transpose(0,1), True) # the transpose makes dims compatible (catofthecannals)\n",
    "\n",
    "error_rates_per_epoch = []\n",
    "for epoch in range(EPOCH_SIZE):\n",
    "    \n",
    "    print(\"EPOCH {} STARTED\".format(epoch))\n",
    "\n",
    "    error_rates_per_batch = []\n",
    "    i = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for instance_batch, label_batch in train_loader:\n",
    "        # Step 1. Pytorch accumulates gradients.  We need to clear them out\n",
    "        # before each instance\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        instance_batch = instance_batch.transpose(0,1)\n",
    "\n",
    "        # Step 2. Run our forward pass\n",
    "        log_probs = model(instance_batch)\n",
    "\n",
    "        # Step 3. Compute the loss, gradients, and update the parameters by calling\n",
    "        # optimizer.step()\n",
    "        loss = loss_function(log_probs, label_batch) # gets the a scalar value held in the loss\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), CLIP) # Gradient clip to avoid exploding gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "    # at the end of each epoc, log the loss and the acc of the last batch.\n",
    "    running_loss = loss.item()\n",
    "    _, predicted = torch.max(log_probs, 1)\n",
    "    error_rate = calculate_error_rate(predicted, label_batch)\n",
    "\n",
    "    with SummaryWriter(\"./hello_tf_board/\") as writer:\n",
    "        writer.add_scalar('accuracy', error_rate, epoch)\n",
    "        writer.add_scalar('loss function', running_loss, epoch)\n",
    "    \n",
    "    print(\"EPOCH {} ENDED:  accuracy: {}\".format(epoch, error_rate))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
